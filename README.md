# Speech-Language-Identification-System 
This project was a part of a homework problem for the course *EE 599 Deep Learning* </br> </br>
Instructions to use the code: </br>
1. mfcc_gen.py - PREPROCESSING - This converts wav files from dataset into 3 sets of mfcc files - training file, test file and validation file. No speakers overlap in any 	of these 3 files.</br> To create mfcc from new datafiles update 'data_file' [line 8] 	and 'datapath' [line 6] </br> </br>

2. train.py - TRAINING - This builds and trains the model. </br>
	To run this file: </br>
	I. 6 datasets are needed (prepared from mfcc_gen.py, could not submitted to canvas 	- very large files(2GB)): </br>
		(i) 3 MFCC feature datasets: mfcc_train.npz, mfcc_test.npz, mfcc_val.npz </br>
		(ii) 3 Label datasets: l_train.npz, l_test.npz, l_val.npz </br>

	II. After downloading above datasets, in train.py update 'datapath' [line 22] to 	the path where the datasets are. NO CHANGES IF IN SAME DIRECTORY. </br>

	III. Update the 'modelpath' to where the trained model will be saved [line 23].NO 	CHANGES IF IN SAME DIRECTORY. </br>

	IV. Change number of epochs (if required): EPOCHS in [line 27]. Default = 40 </br>
 
	IV. Run train.py (uses GPU, if available) </br> </br>

3. test.py - TESTING - No pre-downloaded dataset needed. Takes a test json file as input 	and does all pre-processing in 1 file. </br>
	Note: Uncomment first section to convert wav to mfcc and update 'data_file' [line 	33] </br>
	This has two phases: </br>
	I. Part 1 - (Non-streaming model) Test-accuracy of the model on a test file </br>
	II. Part 2 - (Streaming model) The above dataset is fed to a streaming model </br> </br> </br>


SUMMARY OF MODEL AND RESULTS </br> </br>

Model details: 1 FC layer(32 units) followed by  2 GRU layers (64 and 32 units respectively) . Optimizer = Adam(1e-03), Batch-size = 64, epochs = 20. To avoid over-fitting: l2 kernel and recurrent regularization, dropout = 0.2, recurrent dropout = 0.2, loss = sparse categorical cross-entropy </br>

Training Accuracy: 87.5%</br>
Test Accuracy (generated by non-overlapping speakers): 59.5%</br></br>
